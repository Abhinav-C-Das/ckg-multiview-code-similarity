Below is a **clean, accurate, paper-grade `README.md`** that reflects **exactly** the project state you reached in this chat â€” including the fixes, design decisions, and how to run/evaluate everything.

You can drop this directly at the project root.

---

# ğŸ“˜ Code Similarity via CPG-Based Structural & Semantic Features

This repository implements a **research-grade code similarity and retrieval pipeline** using **Code Property Graphs (CPGs)** built with **Joern 4.x**.
The system extracts **structural**, **semantic**, and **behavioral** features from C programs, converts them into vectors, computes similarity, and evaluates retrieval accuracy against ground truth.

The pipeline is optimized for:

* **Studentâ€“reference code comparison**
* **Intra-procedural analysis**
* **Fast, stable execution (no PDG / no full dataflow)**

---

## ğŸ§  Key Design Decisions (Important)

These are **intentional**, not limitations:

* âŒ **No global PDG / runDataflow**

  * Avoids hangs and huge memory overhead in Joern 4.x
  * Semantic features use **local defâ€“use**, which is sufficient and standard in literature
* âœ… **Intra-procedural defâ€“use only**
* âœ… **Conservative semantic features** (fire only when real semantic patterns exist)
* âœ… **Log-tolerant parsing** (Joern output may contain INFO logs)

This design aligns with **structure-based code assessment models (SBCAM-style systems)**.

---

## ğŸ“‚ Project Structure

```text
ckg_f2/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ p1/
â”‚       â”œâ”€â”€ ref/
â”‚       â”‚   â”œâ”€â”€ ref1.c
â”‚       â”‚   â”œâ”€â”€ ref2.c
â”‚       â”‚   â””â”€â”€ ref3.c
â”‚       â””â”€â”€ s/
â”‚           â”œâ”€â”€ s1.c
â”‚           â”œâ”€â”€ s2.c
â”‚           â”œâ”€â”€ s3.c
â”‚           â””â”€â”€ s_semantic.c   # semantic-rich validation program
â”‚
â”œâ”€â”€ outputs/
â”‚   â””â”€â”€ p1/
â”‚       â”œâ”€â”€ ref/
â”‚       â”‚   â””â”€â”€ ref1/
â”‚       â”‚       â”œâ”€â”€ cpg.bin
â”‚       â”‚       â”œâ”€â”€ canonical.json
â”‚       â”‚       â”œâ”€â”€ structural.json
â”‚       â”‚       â”œâ”€â”€ semantic.json
â”‚       â”‚       â”œâ”€â”€ behavioral.json
â”‚       â”‚       â””â”€â”€ combined_features.json
â”‚       â””â”€â”€ s/
â”‚           â””â”€â”€ s3/
â”‚               â””â”€â”€ (same structure as above)
â”‚
â”œâ”€â”€ vectors/
â”‚   â””â”€â”€ baseline/
â”‚       â”œâ”€â”€ p1_ref_ref1.vec
â”‚       â”œâ”€â”€ p1_ref_ref1.norm.vec
â”‚       â”œâ”€â”€ p1_s_s1.vec
â”‚       â””â”€â”€ ...
â”‚
â”œâ”€â”€ cpg/
â”‚   â””â”€â”€ scripts/
â”‚       â”œâ”€â”€ preprocess/
â”‚       â”‚   â””â”€â”€ canonicalize.sc
â”‚       â”œâ”€â”€ structural/
â”‚       â”‚   â””â”€â”€ basic_structural.sc
â”‚       â”œâ”€â”€ semantic/
â”‚       â”‚   â””â”€â”€ basic_semantic.sc   # FIXED: local defâ€“use (no dataflow)
â”‚       â””â”€â”€ behavioral/
â”‚           â””â”€â”€ basic_behavioral.sc
â”‚
â”œâ”€â”€ similarity/
â”‚   â”œâ”€â”€ aggregate_baseline.py
â”‚   â”œâ”€â”€ vectorize_features.py
â”‚   â”œâ”€â”€ normalize.py
â”‚   â””â”€â”€ similarity.py
â”‚
â”œâ”€â”€ evaluation/
â”‚   â”œâ”€â”€ similarity_matrix.json
â”‚   â”œâ”€â”€ ground_truth.json
â”‚   â”œâ”€â”€ run_similarity_matrix.py
â”‚   â””â”€â”€ run_retrieval_evaluation.py
â”‚
â”œâ”€â”€ run_joern.sh
â”œâ”€â”€ run_baseline_pipeline.sh
â”œâ”€â”€ run_full_pipeline.sh
â””â”€â”€ README.md
```

---

## ğŸ§© Feature Extraction

### 1ï¸âƒ£ Structural Features (`basic_structural.sc`)

Extracted from AST & CFG:

* AST node count
* AST depth (max / average)
* AST node type histogram
* CFG node count
* CFG edge count
* Loop count
* Conditional count

â¡ Always available (no dataflow required).

---

### 2ï¸âƒ£ Semantic Features (`basic_semantic.sc`) **(FIXED)**

Uses **local, intra-procedural defâ€“use only**:

* `def_use_edges`
* `def_use_density`
* `control_predicates`
* `control_data_ratio`
* `param_return_ratio`
* `param_output_ratio`

âš ï¸ **No `runDataflow()`**

* Prevents hangs
* Prevents memory blowups
* Matches research practice

---

### 3ï¸âƒ£ Behavioral Features (`basic_behavioral.sc`)

Binary flags:

* `recursion_present`
* `iterative_present`
* `base_case_present`

---

### 4ï¸âƒ£ Combined Features

Each program produces:

```json
{
  "structural": { ... },
  "semantic": { ... },
  "behavioral": { ... }
}
```

Saved as:

```
outputs/<problem>/<role>/<program>/combined_features.json
```

---

## ğŸ” Pipelines

### ğŸ”¹ `run_joern.sh`

* Builds CPGs
* Runs canonicalization
* Extracts structural, semantic, behavioral features
* Writes JSON files per program

âš ï¸ Redirects **stderr**, not stdout, to handle Joern logs safely.

---

### ğŸ”¹ `run_baseline_pipeline.sh`

* Aggregates feature JSONs
* Converts them into fixed-length vectors
* Normalizes vectors (L2 / MinMax)
* Stores vectors in `vectors/baseline/`

---

### ğŸ”¹ `run_full_pipeline.sh`

Runs **everything end-to-end**:

```bash
./run_joern.sh
./run_baseline_pipeline.sh
```

---

## â–¶ï¸ How to Run the Project

### 1ï¸âƒ£ Prerequisites

* Linux
* Joern 4.x (`joern`, `joern-parse` on PATH)
* Python 3.8+
* `jq`

---

### 2ï¸âƒ£ Clean Run (Recommended)

```bash
rm -rf outputs vectors
./run_full_pipeline.sh
```

---

### 3ï¸âƒ£ Inspect Extracted Features

```bash
jq . outputs/p1/s/s3/combined_features.json
```

To inspect raw semantic output (log-tolerant):

```bash
sed -n '/^{/,$p' outputs/p1/s/s_semantic/semantic.json | jq .
```

---

## ğŸ“ Similarity Computation

### ğŸ”¹ `similarity/similarity.py`

* Computes cosine similarity
* Feature-aware (structural / semantic / behavioral ranges)
* Outputs:

  * structural similarity
  * semantic similarity
  * behavioral similarity
  * overall similarity

---

### ğŸ”¹ Similarity Matrix

```bash
python3 evaluation/run_similarity_matrix.py
```

Produces:

```
evaluation/similarity_matrix.json
```

Format:

```json
{
  "p1": {
    "p1_s_s1": {
      "p1_ref_ref1": { "overall_similarity": 0.82 },
      ...
    }
  }
}
```

---

## ğŸ¯ Evaluation

### Ground Truth

Stored in:

```
evaluation/ground_truth.json
```

Example:

```json
{
  "p1_s1": "p1_ref1",
  "p1_s2": "p1_ref3"
}
```

---

### Retrieval Evaluation

```bash
python3 evaluation/run_retrieval_evaluation.py
```

Outputs:

```json
{
  "accuracy": 0.83,
  "total": 12,
  "correct": 10
}
```

---

## âœ… Validation Performed

* âœ” Structural features vary meaningfully
* âœ” Semantic features fire when appropriate
* âœ” Behavioral flags correct
* âœ” No hangs / no PDG
* âœ” Stable performance
* âœ” Defensible design for publication

---

## ğŸ§  Final Notes

This pipeline is:

* **Fast**
* **Stable**
* **Explainable**
* **Research-defensible**

It avoids common Joern pitfalls (full dataflow misuse) while still capturing meaningful semantic signal.

---

If you want next:

* feature weighting strategy
* CES integration README
* experiment results template
* paper-ready methodology section

Just say the word.
